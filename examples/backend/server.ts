/**
 * Backend Proxy Server Ð´Ð»Ñ LLM API
 * 
 * Ð’Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸:
 * - SSE streaming Ð¾Ñ‚ OpenAI Ðº ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ
 * - Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾Ðµ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ API ÐºÐ»ÑŽÑ‡ÐµÐ¹
 * - Rate limiting
 * - Input validation
 * - Error handling
 * - CORS Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°
 * 
 * Ð¡Ñ‚ÐµÐº:
 * - Node.js + Express
 * - TypeScript
 * - OpenAI SDK
 */

import express, { Request, Response, NextFunction } from 'express';
import cors from 'cors';
import dotenv from 'dotenv';
import rateLimit from 'express-rate-limit';
import OpenAI from 'openai';

// Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ðµ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
dotenv.config();

/* ============================================================================
 * Configuration
 * ========================================================================= */

const app = express();
const PORT = process.env.PORT || 3001;

// Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ OpenAI ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð°
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

/* ============================================================================
 * Middleware
 * ========================================================================= */

// CORS - Ñ€Ð°Ð·Ñ€ÐµÑˆÐ°ÐµÐ¼ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ñ frontend
app.use(
  cors({
    origin: process.env.FRONTEND_URL || 'http://localhost:5173',
    credentials: true,
  })
);

// JSON parser
app.use(express.json({ limit: '10mb' }));

// Rate limiting - Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ DDoS
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 Ð¼Ð¸Ð½ÑƒÑ‚
  max: 100, // Ð¼Ð°ÐºÑ 100 Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð² Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ IP
  message: {
    error: 'Too many requests from this IP, please try again later',
  },
  standardHeaders: true,
  legacyHeaders: false,
});

app.use('/api/', limiter);

// Request logging
app.use((req: Request, res: Response, next: NextFunction) => {
  console.log(`[${new Date().toISOString()}] ${req.method} ${req.path}`);
  next();
});

/* ============================================================================
 * Types
 * ========================================================================= */

interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface ChatRequest {
  messages: ChatMessage[];
  model?: string;
  temperature?: number;
  max_tokens?: number;
}

/* ============================================================================
 * Validation
 * ========================================================================= */

/**
 * Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ð¹
 */
function validateMessages(messages: any): messages is ChatMessage[] {
  if (!Array.isArray(messages)) {
    return false;
  }

  if (messages.length === 0 || messages.length > 50) {
    return false;
  }

  return messages.every(
    (msg) =>
      msg &&
      typeof msg === 'object' &&
      ['system', 'user', 'assistant'].includes(msg.role) &&
      typeof msg.content === 'string' &&
      msg.content.length > 0 &&
      msg.content.length <= 10000
  );
}

/**
 * ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° prompt injection
 */
function checkPromptInjection(text: string): boolean {
  const dangerousPatterns = [
    /ignore\s+(previous|all|above)\s+(instructions|prompts|rules)/i,
    /disregard\s+all/i,
    /you\s+are\s+now/i,
    /Ð½Ð¾Ð²Ñ‹Ðµ\s+Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ð¸/i,
    /<\|im_start\|>/i,
    /\[SYSTEM\]/i,
  ];

  return dangerousPatterns.some((pattern) => pattern.test(text));
}

/**
 * Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ Ð·Ð°Ð¿Ñ€Ð¾ÑÐ°
 */
function validateChatRequest(body: any): body is ChatRequest {
  if (!body || typeof body !== 'object') {
    return false;
  }

  if (!validateMessages(body.messages)) {
    return false;
  }

  // ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° prompt injection
  for (const msg of body.messages) {
    if (checkPromptInjection(msg.content)) {
      return false;
    }
  }

  return true;
}

/* ============================================================================
 * Routes
 * ========================================================================= */

/**
 * Health Check
 */
app.get('/health', (req: Request, res: Response) => {
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
  });
});

/**
 * ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ð¹ Chat Completion (Ð±ÐµÐ· streaming)
 */
app.post('/api/chat', async (req: Request, res: Response) => {
  try {
    // Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
    if (!validateChatRequest(req.body)) {
      return res.status(400).json({
        error: 'Invalid request format or potentially malicious content',
      });
    }

    const { messages, model = 'gpt-4-turbo-preview', temperature = 0.7 } = req.body;

    // Ð’Ñ‹Ð·Ð¾Ð² OpenAI API
    const completion = await openai.chat.completions.create({
      model: model,
      messages: messages,
      temperature: temperature,
      max_tokens: 1000,
    });

    const response = completion.choices[0].message.content || '';

    res.json({
      message: response,
      usage: completion.usage,
    });
  } catch (error: any) {
    console.error('Chat error:', error);
    
    res.status(500).json({
      error: 'Failed to generate response',
      message: error.message || 'Unknown error',
    });
  }
});

/**
 * Streaming Chat Completion
 */
app.post('/api/chat/stream', async (req: Request, res: Response) => {
  try {
    // Ð’Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ñ
    if (!validateChatRequest(req.body)) {
      return res.status(400).json({
        error: 'Invalid request format or potentially malicious content',
      });
    }

    const {
      messages,
      model = 'gpt-4-turbo-preview',
      temperature = 0.7,
      max_tokens = 2000,
    } = req.body;

    // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ SSE
    res.setHeader('Content-Type', 'text/event-stream');
    res.setHeader('Cache-Control', 'no-cache');
    res.setHeader('Connection', 'keep-alive');
    
    // Ð”Ð»Ñ CORS
    res.setHeader('Access-Control-Allow-Origin', process.env.FRONTEND_URL || '*');

    // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ streaming Ð·Ð°Ð¿Ñ€Ð¾Ñ Ðº OpenAI
    const stream = await openai.chat.completions.create({
      model: model,
      messages: messages,
      temperature: temperature,
      max_tokens: max_tokens,
      stream: true,
    });

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ‚Ð¾ÐºÐµÐ½Ñ‹ Ð¿Ð¾ Ð¼ÐµÑ€Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ
    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content;

      if (content) {
        // Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ SSE: "data: {JSON}\n\n"
        const data = JSON.stringify({ content });
        res.write(`data: ${data}\n\n`);
      }

      // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ð½Ðµ Ð·Ð°ÐºÑ€Ñ‹Ð» Ð»Ð¸ ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ
      if (res.writableEnded) {
        break;
      }
    }

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¸Ð³Ð½Ð°Ð» Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ
    res.write(`data: [DONE]\n\n`);
    res.end();
  } catch (error: any) {
    console.error('Streaming error:', error);

    // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¾ÑˆÐ¸Ð±ÐºÑƒ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ SSE
    const errorData = JSON.stringify({
      error: 'Stream failed',
      message: error.message || 'Unknown error',
    });
    res.write(`data: ${errorData}\n\n`);
    res.end();
  }
});

/**
 * OpenAI Moderation API
 */
app.post('/api/moderation', async (req: Request, res: Response) => {
  try {
    const { text } = req.body;

    if (!text || typeof text !== 'string') {
      return res.status(400).json({ error: 'Invalid text' });
    }

    const moderation = await openai.moderations.create({
      input: text,
    });

    const result = moderation.results[0];

    res.json({
      safe: !result.flagged,
      categories: result.categories,
      category_scores: result.category_scores,
    });
  } catch (error: any) {
    console.error('Moderation error:', error);
    res.status(500).json({
      error: 'Moderation failed',
      message: error.message,
    });
  }
});

/* ============================================================================
 * Error Handling
 * ========================================================================= */

// 404 Handler
app.use((req: Request, res: Response) => {
  res.status(404).json({
    error: 'Not found',
    path: req.path,
  });
});

// Global Error Handler
app.use((err: Error, req: Request, res: Response, next: NextFunction) => {
  console.error('Unhandled error:', err);

  res.status(500).json({
    error: 'Internal server error',
    message: process.env.NODE_ENV === 'development' ? err.message : 'Something went wrong',
  });
});

/* ============================================================================
 * Server Start
 * ========================================================================= */

const server = app.listen(PORT, () => {
  console.log('ðŸš€ Server started');
  console.log(`ðŸ“¡ Listening on http://localhost:${PORT}`);
  console.log(`ðŸŒ Environment: ${process.env.NODE_ENV || 'development'}`);
  console.log(`ðŸ”‘ OpenAI API Key: ${process.env.OPENAI_API_KEY ? 'âœ“ Set' : 'âœ— Missing'}`);
});

/* ============================================================================
 * Graceful Shutdown
 * ========================================================================= */

process.on('SIGTERM', () => {
  console.log('SIGTERM received, closing server gracefully...');
  
  server.close(() => {
    console.log('Server closed');
    process.exit(0);
  });
});

process.on('SIGINT', () => {
  console.log('SIGINT received, closing server gracefully...');
  
  server.close(() => {
    console.log('Server closed');
    process.exit(0);
  });
});

// ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½ÐµÐ¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… Ð¿Ñ€Ð¾Ð¼Ð¸ÑÐ¾Ð²
process.on('unhandledRejection', (reason, promise) => {
  console.error('Unhandled Rejection at:', promise, 'reason:', reason);
});

export default app;
